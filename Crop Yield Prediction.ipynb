{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e14174-ac9f-4f6e-97ee-f57eb903406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field_id           90\n",
      "date_of_image      25\n",
      "latitude           90\n",
      "longitude          90\n",
      "NDVI             1588\n",
      "GNDVI            1588\n",
      "NDWI             1588\n",
      "SAVI             1588\n",
      "soil_moisture    1588\n",
      "temperature      1625\n",
      "rainfall         1446\n",
      "crop_type          30\n",
      "yield            1198\n",
      "Unnamed: 13         0\n",
      "Unnamed: 14         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# summarize the number of unique values for each column using numpy\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "df = read_csv('yield_prediction_dataset.csv')\n",
    "# summarize the number of unique values in each column\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e1c074-6a0e-40cf-8c96-31c4b6bc6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values per column:\n",
      " field_id           90\n",
      "date_of_image      25\n",
      "latitude           90\n",
      "longitude          90\n",
      "NDVI             1588\n",
      "GNDVI            1588\n",
      "NDWI             1588\n",
      "SAVI             1588\n",
      "soil_moisture    1588\n",
      "temperature      1625\n",
      "rainfall         1446\n",
      "crop_type          30\n",
      "yield            1198\n",
      "dtype: int64 \n",
      "\n",
      "Number of duplicate rows: 0 \n",
      "\n",
      "Missing values per column:\n",
      " field_id         0\n",
      "date_of_image    0\n",
      "latitude         0\n",
      "longitude        0\n",
      "NDVI             0\n",
      "GNDVI            0\n",
      "NDWI             0\n",
      "SAVI             0\n",
      "soil_moisture    0\n",
      "temperature      0\n",
      "rainfall         0\n",
      "crop_type        0\n",
      "yield            0\n",
      "dtype: int64 \n",
      "\n",
      "Outliers detected per column:\n",
      " {'latitude': 0, 'longitude': 106, 'NDVI': 33, 'GNDVI': 104, 'NDWI': 104, 'SAVI': 33, 'soil_moisture': 89, 'temperature': 0, 'rainfall': 15, 'yield': 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"yield_prediction_dataset.csv\")\n",
    "\n",
    "# Unique values per column\n",
    "print(\"Unique values per column:\\n\", df.nunique(), \"\\n\")\n",
    "\n",
    "# Duplicate rows count\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum(), \"\\n\")\n",
    "\n",
    "# Missing values per column\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum(), \"\\n\")\n",
    "\n",
    "# Detect outliers using the IQR method\n",
    "outliers = {}\n",
    "for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_condition = (df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR))\n",
    "    outliers[column] = outlier_condition.sum()\n",
    "\n",
    "print(\"Outliers detected per column:\\n\", outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6748494-abab-4fdb-8e1a-7f5f071e2101",
   "metadata": {},
   "source": [
    "Significant outliers in:\n",
    "\n",
    "longitude (106 values)\n",
    "\n",
    "NDVI, GNDVI, NDWI, SAVI\n",
    "\n",
    "soil_moisture (89 values)\n",
    "\n",
    "rainfall (15 values)\n",
    "\n",
    "yield (3 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdd5f5-a207-43e1-9c36-800dac5027d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d8171-46cc-4fdd-8cc3-e83124861312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742957eb-e09a-4a7b-8670-bf8b79ffbf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37d230a5-8899-486e-adcc-c3c8b2483170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Outliers removed and cleaned dataset saved to 'yield_prediction1.csv'\n",
      "Original shape: (1625, 40)\n",
      "New shape:      (1389, 40)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('yield_prediction_dataset.csv')\n",
    "\n",
    "# Drop non-numeric or irrelevant columns\n",
    "df.drop(columns=['field_id', 'date_of_image'], inplace=True)\n",
    "\n",
    "# One-hot encode the 'crop_type' feature\n",
    "df = pd.get_dummies(df, columns=['crop_type'])\n",
    "\n",
    "# Drop any column with all NaN values\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Fill remaining missing values with the mean (numeric columns only)\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Function to remove outliers using the IQR method\n",
    "def remove_outliers_iqr(data):\n",
    "    df_clean = data.copy()\n",
    "    numeric_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# Apply outlier removal\n",
    "df_no_outliers = remove_outliers_iqr(df)\n",
    "\n",
    "# Save cleaned data to new CSV file\n",
    "df_no_outliers.to_csv('yield_prediction1.csv', index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"✅ Outliers removed and cleaned dataset saved to 'yield_prediction1.csv'\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"New shape:      {df_no_outliers.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a04f9ac0-e4b7-40d8-9e3a-eaece0d1a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Remaining Outliers in Cleaned Data ===\n",
      "           Outlier Count\n",
      "longitude             92\n",
      "GNDVI                  3\n",
      "NDWI                   3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Function to detect outliers using IQR\n",
    "def detect_outliers(df, columns):\n",
    "    outliers = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outliers[col] = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "    return outliers\n",
    "\n",
    "# Detect outliers in all numeric columns\n",
    "numeric_columns = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "outlier_counts = detect_outliers(df, numeric_columns)\n",
    "\n",
    "# Display the results\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_counts, orient=\"index\", columns=[\"Outlier Count\"])\n",
    "outlier_df = outlier_df[outlier_df[\"Outlier Count\"] > 0]  # Show only columns that still have outliers\n",
    "\n",
    "print(\"=== Remaining Outliers in Cleaned Data ===\")\n",
    "print(outlier_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "923bf228-3e0d-4e01-b7b9-15736008d7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All remaining outliers removed.\n",
      "New shape: (1289, 40)\n",
      "✔️ File saved as 'yield_prediction1.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load existing cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Function to remove outliers from all numeric columns using IQR\n",
    "def remove_all_outliers(df):\n",
    "    df_clean = df.copy()\n",
    "    numeric_cols = df_clean.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Apply outlier removal\n",
    "df_fully_cleaned = remove_all_outliers(df)\n",
    "\n",
    "# Save the fully cleaned dataset (overwrite same file)\n",
    "df_fully_cleaned.to_csv(\"yield_prediction1.csv\", index=False)\n",
    "\n",
    "# Summary\n",
    "print(\"✅ All remaining outliers removed.\")\n",
    "print(f\"New shape: {df_fully_cleaned.shape}\")\n",
    "print(\"✔️ File saved as 'yield_prediction1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71614e39-cb0d-450e-8395-ca0fa6d166c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Remaining Outliers in Cleaned Data ===\n",
      "       Outlier Count\n",
      "GNDVI              1\n",
      "NDWI               1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Function to detect outliers using IQR\n",
    "def detect_outliers(df, columns):\n",
    "    outliers = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outliers[col] = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "    return outliers\n",
    "\n",
    "# Detect outliers in all numeric columns\n",
    "numeric_columns = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "outlier_counts = detect_outliers(df, numeric_columns)\n",
    "\n",
    "# Display the results\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_counts, orient=\"index\", columns=[\"Outlier Count\"])\n",
    "outlier_df = outlier_df[outlier_df[\"Outlier Count\"] > 0]  # Show only columns that still have outliers\n",
    "\n",
    "print(\"=== Remaining Outliers in Cleaned Data ===\")\n",
    "print(outlier_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "368620a5-1132-41e7-b954-8ef86186dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final outliers from GNDVI and NDWI removed.\n",
      "Final shape: (1288, 40)\n",
      "✔️ File saved as 'yield_prediction1.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the current version of the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# List of columns to clean\n",
    "columns_to_clean = ['GNDVI', 'NDWI']\n",
    "\n",
    "# IQR-based removal for specific columns\n",
    "for col in columns_to_clean:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "# Save the updated cleaned dataset\n",
    "df.to_csv(\"yield_prediction1.csv\", index=False)\n",
    "\n",
    "# Report\n",
    "print(\"✅ Final outliers from GNDVI and NDWI removed.\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(\"✔️ File saved as 'yield_prediction1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3818b0d-372e-42b5-89ba-1e129b461260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Remaining Outliers in Cleaned Data ===\n",
      "Empty DataFrame\n",
      "Columns: [Outlier Count]\n",
      "Index: []\n",
      "Final shape: (1288, 40)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Function to detect outliers using IQR\n",
    "def detect_outliers(df, columns):\n",
    "    outliers = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outliers[col] = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "    return outliers\n",
    "\n",
    "# Detect outliers in all numeric columns\n",
    "numeric_columns = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "outlier_counts = detect_outliers(df, numeric_columns)\n",
    "\n",
    "# Display the results\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_counts, orient=\"index\", columns=[\"Outlier Count\"])\n",
    "outlier_df = outlier_df[outlier_df[\"Outlier Count\"] > 0]  # Show only columns that still have outliers\n",
    "\n",
    "print(\"=== Remaining Outliers in Cleaned Data ===\")\n",
    "print(outlier_df)\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "# Save the updated cleaned dataset\n",
    "df.to_csv(\"yield_prediction1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b559da1c-48d2-4f06-a9f3-8d3b8f554362",
   "metadata": {},
   "source": [
    " dataset should be 100% outlier-free across all numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e6ede-a63b-415f-b676-f6234eb083d8",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7f8f2a4-d619-4fa9-bbee-7ebe70b609c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Regression Results ===\n",
      "   Model  R2 Score        MSE\n",
      "0  KNN-1  0.833883  10.838827\n",
      "1  KNN-3  0.846104  10.041471\n",
      "2  KNN-9  0.852813   9.603700\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Instantiate KNN regressors\n",
    "reg_01 = KNeighborsRegressor(n_neighbors=1)\n",
    "reg_03 = KNeighborsRegressor(n_neighbors=3)\n",
    "reg_09 = KNeighborsRegressor(n_neighbors=9)\n",
    "\n",
    "# Fit the models\n",
    "reg_01.fit(X_train, y_train)\n",
    "reg_03.fit(X_train, y_train)\n",
    "reg_09.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"R2 Score\": [],\n",
    "    \"MSE\": []\n",
    "}\n",
    "\n",
    "for model, label in zip([reg_01, reg_03, reg_09], [\"KNN-1\", \"KNN-3\", \"KNN-9\"]):\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    results[\"Model\"].append(label)\n",
    "    results[\"R2 Score\"].append(r2)\n",
    "    results[\"MSE\"].append(mse)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"=== KNN Regression Results ===\")\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af2026-ed7f-4e5c-a685-44a669debd28",
   "metadata": {},
   "source": [
    "The KNN-9 model performs best in both metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d286e3fa-faec-4577-8a21-bf9f4f6ded96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Model Performance ===\n",
      "K: 01 Train set R^2: 1.00\n",
      "K: 01 Test set R^2: 0.83\n",
      "K: 03 Train set R^2: 0.93\n",
      "K: 03 Test set R^2: 0.85\n",
      "K: 09 Train set R^2: 0.88\n",
      "K: 09 Test set R^2: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Instantiate models\n",
    "reg_01 = KNeighborsRegressor(n_neighbors=1)\n",
    "reg_03 = KNeighborsRegressor(n_neighbors=3)\n",
    "reg_09 = KNeighborsRegressor(n_neighbors=9)\n",
    "\n",
    "# Fit models\n",
    "reg_01.fit(X_train, y_train)\n",
    "reg_03.fit(X_train, y_train)\n",
    "reg_09.fit(X_train, y_train)\n",
    "\n",
    "# Print performance for each model\n",
    "print(\"=== KNN Model Performance ===\")\n",
    "print(\"K: 01 Train set R^2: {:.2f}\".format(reg_01.score(X_train, y_train)))\n",
    "print(\"K: 01 Test set R^2: {:.2f}\".format(reg_01.score(X_test, y_test)))\n",
    "print(\"K: 03 Train set R^2: {:.2f}\".format(reg_03.score(X_train, y_train)))\n",
    "print(\"K: 03 Test set R^2: {:.2f}\".format(reg_03.score(X_test, y_test)))\n",
    "print(\"K: 09 Train set R^2: {:.2f}\".format(reg_09.score(X_train, y_train)))\n",
    "print(\"K: 09 Test set R^2: {:.2f}\".format(reg_09.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad308c8-176f-4c97-b9f4-34b47d4b1606",
   "metadata": {},
   "source": [
    "## The KNN-9 model performs best in both metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42926dc-ef1f-48cb-a054-1b976accf825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1de6a6d3-9317-40bb-927e-72f18b5383f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Model Performance (With Scaling) ===\n",
      "K: 01 Train set R^2: 1.00\n",
      "K: 01 Test set R^2: 0.72\n",
      "K: 03 Train set R^2: 0.89\n",
      "K: 03 Test set R^2: 0.74\n",
      "K: 09 Train set R^2: 0.68\n",
      "K: 09 Test set R^2: 0.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Apply StandardScaler to features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate models\n",
    "reg_01 = KNeighborsRegressor(n_neighbors=1)\n",
    "reg_03 = KNeighborsRegressor(n_neighbors=3)\n",
    "reg_9 = KNeighborsRegressor(n_neighbors=9)\n",
    "\n",
    "# Fit models using scaled data\n",
    "reg_01.fit(X_train_scaled, y_train)\n",
    "reg_03.fit(X_train_scaled, y_train)\n",
    "reg_9.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print performance for each model\n",
    "print(\"=== KNN Model Performance (With Scaling) ===\")\n",
    "print(\"K: 01 Train set R^2: {:.2f}\".format(reg_01.score(X_train_scaled, y_train)))\n",
    "print(\"K: 01 Test set R^2: {:.2f}\".format(reg_01.score(X_test_scaled, y_test)))\n",
    "print(\"K: 03 Train set R^2: {:.2f}\".format(reg_03.score(X_train_scaled, y_train)))\n",
    "print(\"K: 03 Test set R^2: {:.2f}\".format(reg_03.score(X_test_scaled, y_test)))\n",
    "print(\"K: 09 Train set R^2: {:.2f}\".format(reg_9.score(X_train_scaled, y_train)))\n",
    "print(\"K: 09 Test set R^2: {:.2f}\".format(reg_9.score(X_test_scaled, y_test)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb30c6df-67f0-4b78-a7b5-c194e525f7be",
   "metadata": {},
   "source": [
    "✅ Linear Regression\n",
    "✅ Ridge Regression\n",
    "✅ Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a14829a-69e5-446c-b2ef-41c008cf0c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regression Models Evaluation without StandardScaler ===\n",
      "               Model  Train R2   Test R2  Train MSE  Test MSE\n",
      "0  Linear Regression  0.859463  0.844940   9.078636  9.580304\n",
      "1   Ridge Regression  0.857931  0.846359   9.177605  9.492616\n",
      "2   Lasso Regression  0.856189  0.845627   9.290143  9.537805\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Step 1: Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Step 2: Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Step 3: Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Step 4: Instantiate the models\n",
    "lin_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=1.0)   # alpha=1.0 is default; can be tuned later\n",
    "lasso_reg = Lasso(alpha=0.01)  # small alpha for Lasso; can also be tuned\n",
    "\n",
    "# Step 5: Fit the models\n",
    "lin_reg.fit(X_train, y_train)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate models\n",
    "models = {\n",
    "    \"Linear Regression\": lin_reg,\n",
    "    \"Ridge Regression\": ridge_reg,\n",
    "    \"Lasso Regression\": lasso_reg\n",
    "}\n",
    "\n",
    "# Collect results\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"Train R2\": [],\n",
    "    \"Test R2\": [],\n",
    "    \"Train MSE\": [],\n",
    "    \"Test MSE\": []\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"Train R2\"].append(r2_score(y_train, y_train_pred))\n",
    "    results[\"Test R2\"].append(r2_score(y_test, y_test_pred))\n",
    "    results[\"Train MSE\"].append(mean_squared_error(y_train, y_train_pred))\n",
    "    results[\"Test MSE\"].append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Step 7: Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"=== Regression Models Evaluation without StandardScaler ===\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0119c-fcb3-40d4-8ecf-7f327c50476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "egression Models Evaluation with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a7c56f-57e2-4cb5-b366-1accaf336535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Scaled Regression Models Evaluation with StandardScaler ===\n",
      "               Model  Train R2   Test R2  Train MSE  Test MSE\n",
      "0  Linear Regression  0.859463  0.844952   9.078629  9.579513\n",
      "1   Ridge Regression  0.858974  0.846346   9.110229  9.493386\n",
      "2   Lasso Regression  0.858869  0.846712   9.117034  9.470766\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Step 1: Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Step 2: Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Step 3: Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Step 4: Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 5: Instantiate the models\n",
    "lin_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "lasso_reg = Lasso(alpha=0.01)\n",
    "\n",
    "# Step 6: Fit the models\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "lasso_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 7: Evaluate models\n",
    "models = {\n",
    "    \"Linear Regression\": lin_reg,\n",
    "    \"Ridge Regression\": ridge_reg,\n",
    "    \"Lasso Regression\": lasso_reg\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"Train R2\": [],\n",
    "    \"Test R2\": [],\n",
    "    \"Train MSE\": [],\n",
    "    \"Test MSE\": []\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"Train R2\"].append(r2_score(y_train, y_train_pred))\n",
    "    results[\"Test R2\"].append(r2_score(y_test, y_test_pred))\n",
    "    results[\"Train MSE\"].append(mean_squared_error(y_train, y_train_pred))\n",
    "    results[\"Test MSE\"].append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Step 8: Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"=== Scaled Regression Models Evaluation with StandardScaler ===\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730a0e3-fce0-4cbe-8703-d3a35f259ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    " Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c44b712-b080-4ece-aef9-408e8a6700fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Support Vector Regression (Default) ===\n",
      "Train R2 Score: 0.5484\n",
      "Test R2 Score:  0.5368\n",
      "Train MSE:      28.5476\n",
      "Test MSE:       30.2205\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load your cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Instantiate SVR model with default parameters (kernel='rbf')\n",
    "svr_model = SVR()\n",
    "\n",
    "# Fit the model\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = svr_model.predict(X_train)\n",
    "y_test_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Support Vector Regression (Default) ===\")\n",
    "print(\"Train R2 Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R2 Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbce9271-cf4a-4a6c-a950-d0f91c6f6b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Support Vector Regression (With Scaling) ===\n",
      "Train R2 Score: 0.7885\n",
      "Test R2 Score:  0.7718\n",
      "Train MSE:      13.3691\n",
      "Test MSE:       14.8910\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Apply StandardScaler to features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate SVR with default parameters\n",
    "svr_model = SVR()\n",
    "\n",
    "# Fit the model\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = svr_model.predict(X_train_scaled)\n",
    "y_test_pred = svr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Support Vector Regression (With Scaling) ===\")\n",
    "print(\"Train R2 Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R2 Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab1549-f9d7-432a-88f2-5fafb76befdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078aba6-e566-4928-a7c1-eed3502df721",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - SVR Models by Test R² with Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6339d42-a56f-40bf-841b-7d8934a787d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  SVR Models by Test R² with linear ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>11.6286</td>\n",
       "      <td>11.5287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>11.6286</td>\n",
       "      <td>11.5287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>11.6286</td>\n",
       "      <td>11.5287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>11.7615</td>\n",
       "      <td>11.6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>11.7615</td>\n",
       "      <td>11.6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>11.7615</td>\n",
       "      <td>11.6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>11.7673</td>\n",
       "      <td>11.6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>11.7673</td>\n",
       "      <td>11.6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>11.7673</td>\n",
       "      <td>11.6116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kernel     C  Gamma  Train R2  Test R2  Train MSE  Test MSE\n",
       "0  linear   0.1   0.01    0.8132   0.8298    11.6286   11.5287\n",
       "1  linear   0.1   0.10    0.8132   0.8298    11.6286   11.5287\n",
       "2  linear   0.1   1.00    0.8132   0.8298    11.6286   11.5287\n",
       "3  linear   1.0   0.01    0.8110   0.8287    11.7615   11.6095\n",
       "4  linear   1.0   0.10    0.8110   0.8287    11.7615   11.6095\n",
       "5  linear   1.0   1.00    0.8110   0.8287    11.7615   11.6095\n",
       "6  linear  10.0   0.01    0.8110   0.8286    11.7673   11.6116\n",
       "7  linear  10.0   0.10    0.8110   0.8286    11.7673   11.6116\n",
       "8  linear  10.0   1.00    0.8110   0.8286    11.7673   11.6116"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load the regression dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Apply StandardScaler to features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Parameter grid\n",
    "kernels = ['linear']\n",
    "C_values = [0.1, 1, 10]\n",
    "gamma_values = [0.01, 0.1, 1]\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    for C in C_values:\n",
    "        for gamma in gamma_values:\n",
    "            model = SVR(kernel=kernel, C=C, gamma=gamma)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            results.append({\n",
    "                \"Kernel\": kernel,\n",
    "                \"C\": C,\n",
    "                \"Gamma\": gamma,\n",
    "                \"Train R2\": round(r2_score(y_train, y_train_pred), 4),\n",
    "                \"Test R2\": round(r2_score(y_test, y_test_pred), 4),\n",
    "                \"Train MSE\": round(mean_squared_error(y_train, y_train_pred), 4),\n",
    "                \"Test MSE\": round(mean_squared_error(y_test, y_test_pred), 4)\n",
    "            })\n",
    "\n",
    "\n",
    "# Show the top 10 models\n",
    "print(\"===  SVR Models by Test R² with linear ===\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37367b-7bae-4133-a0a6-10789b201f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 - SVR Models by Test R² with sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9aba6da-8b8d-4b57-a379-f36c9d1c99a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  SVR Models by Test R² with sigmoid ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>46.3375</td>\n",
       "      <td>51.6803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>16.4583</td>\n",
       "      <td>17.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.4152</td>\n",
       "      <td>-0.1932</td>\n",
       "      <td>88.0892</td>\n",
       "      <td>80.8473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8066</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>12.0387</td>\n",
       "      <td>13.3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-4.5906</td>\n",
       "      <td>-3.5807</td>\n",
       "      <td>347.9825</td>\n",
       "      <td>310.3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-102.4870</td>\n",
       "      <td>-85.1566</td>\n",
       "      <td>6441.5083</td>\n",
       "      <td>5837.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>12.9092</td>\n",
       "      <td>11.3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-571.1418</td>\n",
       "      <td>-464.0145</td>\n",
       "      <td>35612.7579</td>\n",
       "      <td>31506.8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-9295.5682</td>\n",
       "      <td>-7988.4201</td>\n",
       "      <td>578661.4553</td>\n",
       "      <td>541320.2645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kernel     C  Gamma   Train R2    Test R2    Train MSE     Test MSE\n",
       "0  sigmoid   0.1   0.01     0.2556     0.2372      46.3375      51.6803\n",
       "1  sigmoid   0.1   0.10     0.7356     0.7448      16.4583      17.2937\n",
       "2  sigmoid   0.1   1.00    -0.4152    -0.1932      88.0892      80.8473\n",
       "3  sigmoid   1.0   0.01     0.8066     0.8036      12.0387      13.3093\n",
       "4  sigmoid   1.0   0.10    -4.5906    -3.5807     347.9825     310.3667\n",
       "5  sigmoid   1.0   1.00  -102.4870   -85.1566    6441.5083    5837.5066\n",
       "6  sigmoid  10.0   0.01     0.7926     0.8323      12.9092      11.3649\n",
       "7  sigmoid  10.0   0.10  -571.1418  -464.0145   35612.7579   31506.8884\n",
       "8  sigmoid  10.0   1.00 -9295.5682 -7988.4201  578661.4553  541320.2645"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load the regression dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Apply StandardScaler to features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Parameter grid\n",
    "kernels = ['sigmoid']\n",
    "C_values = [0.1, 1, 10]\n",
    "gamma_values = [0.01, 0.1, 1]\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    for C in C_values:\n",
    "        for gamma in gamma_values:\n",
    "            model = SVR(kernel=kernel, C=C, gamma=gamma)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            results.append({\n",
    "                \"Kernel\": kernel,\n",
    "                \"C\": C,\n",
    "                \"Gamma\": gamma,\n",
    "                \"Train R2\": round(r2_score(y_train, y_train_pred), 4),\n",
    "                \"Test R2\": round(r2_score(y_test, y_test_pred), 4),\n",
    "                \"Train MSE\": round(mean_squared_error(y_train, y_train_pred), 4),\n",
    "                \"Test MSE\": round(mean_squared_error(y_test, y_test_pred), 4)\n",
    "            })\n",
    "\n",
    "\n",
    "# Show the top 10 models\n",
    "print(\"===  SVR Models by Test R² with sigmoid ===\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0711f-64c5-4c3b-bba1-140326ee8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "3 - SVR Models by Test R² with poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17239863-7ef9-46b4-898d-c26e18cb2020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===  SVR Models by Test R² with poly ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>61.5651</td>\n",
       "      <td>67.6533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>9.7297</td>\n",
       "      <td>17.7927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>1.9261</td>\n",
       "      <td>23.5291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>56.1057</td>\n",
       "      <td>63.0469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>6.0361</td>\n",
       "      <td>12.4056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.2246</td>\n",
       "      <td>1.3367</td>\n",
       "      <td>52.5344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poly</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.3347</td>\n",
       "      <td>34.1957</td>\n",
       "      <td>45.0768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poly</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>3.1329</td>\n",
       "      <td>12.7831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poly</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>-0.4952</td>\n",
       "      <td>1.2919</td>\n",
       "      <td>101.3039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kernel     C  Gamma  Train R2  Test R2  Train MSE  Test MSE\n",
       "0   poly   0.1   0.01    0.0109   0.0015    61.5651   67.6533\n",
       "1   poly   0.1   0.10    0.8437   0.7374     9.7297   17.7927\n",
       "2   poly   0.1   1.00    0.9691   0.6527     1.9261   23.5291\n",
       "3   poly   1.0   0.01    0.0986   0.0695    56.1057   63.0469\n",
       "4   poly   1.0   0.10    0.9030   0.8169     6.0361   12.4056\n",
       "5   poly   1.0   1.00    0.9785   0.2246     1.3367   52.5344\n",
       "6   poly  10.0   0.01    0.4506   0.3347    34.1957   45.0768\n",
       "7   poly  10.0   0.10    0.9497   0.8113     3.1329   12.7831\n",
       "8   poly  10.0   1.00    0.9792  -0.4952     1.2919  101.3039"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load the regression dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Apply StandardScaler to features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Parameter grid\n",
    "kernels = ['poly']\n",
    "C_values = [0.1, 1, 10]\n",
    "gamma_values = [0.01, 0.1, 1]\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    for C in C_values:\n",
    "        for gamma in gamma_values:\n",
    "            model = SVR(kernel=kernel, C=C, gamma=gamma)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            results.append({\n",
    "                \"Kernel\": kernel,\n",
    "                \"C\": C,\n",
    "                \"Gamma\": gamma,\n",
    "                \"Train R2\": round(r2_score(y_train, y_train_pred), 4),\n",
    "                \"Test R2\": round(r2_score(y_test, y_test_pred), 4),\n",
    "                \"Train MSE\": round(mean_squared_error(y_train, y_train_pred), 4),\n",
    "                \"Test MSE\": round(mean_squared_error(y_test, y_test_pred), 4)\n",
    "            })\n",
    "\n",
    "\n",
    "# Show the top 10 models\n",
    "print(\"===  SVR Models by Test R² with poly ===\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51df44-e005-4bd1-85c6-189b1af65941",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor without StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b3cd450-6105-41f2-81d8-b0b6d22dd0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Regressor Performance (No Scaling) ===\n",
      "Train R² Score: 0.9902\n",
      "Test R² Score:  0.9394\n",
      "Train MSE:      0.6006\n",
      "Test MSE:       4.0840\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)\n",
    "\n",
    "# Instantiate and fit RandomForestRegressor (no scaling)\n",
    "rf_model = RandomForestRegressor(n_estimators=500, random_state=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Random Forest Regressor Performance (No Scaling) ===\")\n",
    "print(\"Train R² Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R² Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae701b-419d-4e19-b1b0-23b914f683f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Regressor With StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e23ba69e-892f-4863-9027-f39df5b4b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Regressor (With StandardScaler) ===\n",
      "Train R² Score: 0.9902\n",
      "Test R² Score:  0.9394\n",
      "Train MSE:      0.6006\n",
      "Test MSE:       4.0843\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit model\n",
    "rf_scaled = RandomForestRegressor(n_estimators=500, random_state=100)\n",
    "rf_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = rf_scaled.predict(X_train_scaled)\n",
    "y_test_pred = rf_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Random Forest Regressor (With StandardScaler) ===\")\n",
    "print(\"Train R² Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R² Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8ec58-959a-4e2a-b205-8d4d119cb727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5091df-319e-4cac-bd62-d39b253beccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d4a30-451f-45c7-9258-c5123b96d470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793f2af-1e2b-4f06-b7c2-161463fcddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Code (with tuned parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1a0dadbd-21bd-4c9b-bae4-eb4b32d16865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimized Random Forest Regressor Performance ===\n",
      "Train R² Score: 0.9902\n",
      "Test R² Score:  0.9396\n",
      "Train MSE:      0.6035\n",
      "Test MSE:       4.0666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)\n",
    "\n",
    "# Optimized Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=1000,         # More trees\n",
    "    max_depth=30,              # Deep trees for complexity\n",
    "    min_samples_split=2,       # Default\n",
    "    min_samples_leaf=1,        # Allow fine granularity\n",
    "    max_features=1.0,          # Use all features\n",
    "    bootstrap=True,\n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Train model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Optimized Random Forest Regressor Performance ===\")\n",
    "print(\"Train R² Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R² Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "84a6a470-3f42-4792-803c-a1bc2ae341ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Refined Random Forest Regressor Performance ===\n",
      "Train R² Score: 0.9889\n",
      "Test R² Score:  0.9388\n",
      "Train MSE:      0.6830\n",
      "Test MSE:       4.1207\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)\n",
    "\n",
    "# Refined Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=40,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.8,         # 80% of features per split\n",
    "    bootstrap=True,\n",
    "    random_state=100,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and predict\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Refined Random Forest Regressor Performance ===\")\n",
    "print(\"Train R² Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R² Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fea57-4670-4cd3-bc6b-a20640c5836f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5890ee-d3fa-438d-8fdc-26ac0ec6e254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfc5c6-6fa5-4c4b-bb2a-db3c32f2b2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183ad82-78a4-46d3-98fb-a2434b7198cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3afbfb-5f25-453f-b910-a8df99316f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56070129-f93f-4fe2-b61e-41022c761b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a88dc-6f11-4c53-a1eb-c5d2cfa50144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaefb539-8260-4c5e-93e3-76a0af9626c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision Tree with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6417f5e0-48c3-44c2-bd1f-d7c3d230292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree Regressor (No Scaling) ===\n",
      "Train R² Score: 1.0000\n",
      "Test R² Score:  0.9012\n",
      "Train MSE:      0.0000\n",
      "Test MSE:       6.5005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt = DecisionTreeRegressor(random_state=100)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Decision Tree Regressor (No Scaling) ===\")\n",
    "print(\"Train R² Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R² Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58defc-6041-4216-8576-a01f7b6dc902",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision Tree Without StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "506e537f-8e80-4625-a6d8-b1a827462af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree Regressor (With StandardScaler) ===\n",
      "Train R² Score: 1.0000\n",
      "Test R² Score:  0.9012\n",
      "Train MSE:      0.0000\n",
      "Test MSE:       6.5005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt_scaled = DecisionTreeRegressor(random_state=100)\n",
    "dt_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = dt_scaled.predict(X_train_scaled)\n",
    "y_test_pred = dt_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Decision Tree Regressor (With StandardScaler) ===\")\n",
    "print(\"Train R² Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R² Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea1f7378-8256-446d-a050-8d4705cf321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Regressor (With StandardScaler) ===\n",
      "Train R² Score: 0.9926\n",
      "Test R² Score:  0.9218\n",
      "Train MSE:      0.4754\n",
      "Test MSE:       4.8334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yield_prediction1.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"yield\", axis=1)\n",
    "y = df[\"yield\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit model\n",
    "rf_scaled = RandomForestRegressor(n_estimators=500, random_state=42)\n",
    "rf_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = rf_scaled.predict(X_train_scaled)\n",
    "y_test_pred = rf_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Random Forest Regressor (With StandardScaler) ===\")\n",
    "print(\"Train R² Score: {:.4f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"Test R² Score:  {:.4f}\".format(r2_score(y_test, y_test_pred)))\n",
    "print(\"Train MSE:      {:.4f}\".format(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Test MSE:       {:.4f}\".format(mean_squared_error(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdcb4c6-5799-4dc2-ac82-a361b03a0a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e76d4f-5e67-41aa-832f-8bc022d09bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2df588-077b-4ae0-93fc-747770a3fee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e152d3-b19f-474f-8d67-af67976d2eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
